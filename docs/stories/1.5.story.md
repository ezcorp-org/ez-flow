# Story 1.5: On-Demand Model Download

## Status

Draft

## Story

**As a** user,
**I want** to download only the Whisper model I need,
**so that** I don't waste bandwidth or disk space on unused models.

## Acceptance Criteria

1. Model manifest defines available models: tiny, base, small, medium, large (with sizes)
2. Tauri command `download_model(model_name)` downloads from Hugging Face or mirror
3. Download shows progress percentage via Tauri events
4. Downloaded models stored in platform-appropriate app data directory
5. Integrity verification (checksum) after download
6. Graceful handling of: network errors, interrupted downloads (resume support ideal)
7. Frontend can query which models are already downloaded

## Tasks / Subtasks

- [ ] **Task 1: Define Model Manifest** (AC: 1)
  - [ ] Create `src-tauri/src/services/transcription/models.rs`
  - [ ] Define `WhisperModel` struct with id, name, size_mb, url, sha256
  - [ ] Create static manifest of available models:
    - tiny: 75MB
    - base: 142MB
    - small: 466MB
    - medium: 1500MB
    - large-v3: 3100MB

- [ ] **Task 2: Create Model Storage Service** (AC: 4)
  - [ ] Create `src-tauri/src/services/storage/mod.rs`
  - [ ] Create `src-tauri/src/services/storage/files.rs`
  - [ ] Implement model directory resolution using `directories` crate
  - [ ] Create model directory if not exists
  - [ ] Path: `{app_data}/models/ggml-{model_name}.bin`

- [ ] **Task 3: Implement Download with Progress** (AC: 2, 3)
  - [ ] Add `reqwest` crate with `stream` feature
  - [ ] Implement async download function
  - [ ] Track bytes received vs content-length
  - [ ] Emit `model:download_progress` Tauri events
  - [ ] Save to temp file, then rename on completion

- [ ] **Task 4: Implement Checksum Verification** (AC: 5)
  - [ ] Add `sha2` crate for SHA256
  - [ ] Compute hash while downloading (or after)
  - [ ] Compare with expected hash from manifest
  - [ ] Delete file if checksum fails
  - [ ] Return descriptive error

- [ ] **Task 5: Handle Download Errors** (AC: 6)
  - [ ] Handle network timeout
  - [ ] Handle connection reset
  - [ ] Handle disk full error
  - [ ] Implement basic resume support (Range header)
  - [ ] Clean up partial files on error

- [ ] **Task 6: Create Tauri Commands** (AC: 2, 7)
  - [ ] `get_available_models() -> Vec<WhisperModel>` - List all models with download status
  - [ ] `download_model(model_id: String)` - Download specific model
  - [ ] `delete_model(model_id: String)` - Remove downloaded model
  - [ ] `get_downloaded_models() -> Vec<String>` - List downloaded model IDs

- [ ] **Task 7: Emit Progress Events** (AC: 3)
  - [ ] Define `DownloadProgress` event payload
  - [ ] Emit progress at reasonable intervals (every 1% or 100KB)
  - [ ] Emit completion event
  - [ ] Emit error event on failure

- [ ] **Task 8: Add Unit Tests**
  - [ ] Test model manifest parsing
  - [ ] Test path resolution
  - [ ] Test checksum verification
  - [ ] Mock download for unit tests

## Dev Notes

### Dependencies [Source: architecture.md#2.2]

```toml
[dependencies]
reqwest = { version = "0.11", features = ["stream"] }
sha2 = "0.10"
tokio-util = { version = "0.7", features = ["io"] }
futures-util = "0.3"
```

### Model Manifest [Source: architecture.md#6.3]

```rust
// src-tauri/src/services/transcription/models.rs

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WhisperModel {
    pub id: String,
    pub name: String,
    pub size_mb: u32,
    pub url: String,
    pub sha256: String,
    #[serde(skip)]
    pub downloaded: bool,
}

pub fn get_model_manifest() -> Vec<WhisperModel> {
    vec![
        WhisperModel {
            id: "tiny".into(),
            name: "Tiny (Fast)".into(),
            size_mb: 75,
            url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin".into(),
            sha256: "be07e048e1e599ad46341c8d2a135645097a538221678b4acca1c9f42c9b4690".into(),
            downloaded: false,
        },
        WhisperModel {
            id: "base".into(),
            name: "Base (Balanced)".into(),
            size_mb: 142,
            url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin".into(),
            sha256: "60ed5bc3dd14eea856493d334349b405782ddcaf0028d4b5df4088345fba2efe".into(),
            downloaded: false,
        },
        WhisperModel {
            id: "small".into(),
            name: "Small (Good)".into(),
            size_mb: 466,
            url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin".into(),
            sha256: "1be3a9b2063867b937e64e2ec7483364a79917e157fa98c5d94b5c1fffea987b".into(),
            downloaded: false,
        },
        WhisperModel {
            id: "medium".into(),
            name: "Medium (Better)".into(),
            size_mb: 1500,
            url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin".into(),
            sha256: "6c14d5adee5f86394037b4e4e8b59f1673b6cee10e3cf0b11bbdbee79c156208".into(),
            downloaded: false,
        },
        WhisperModel {
            id: "large-v3".into(),
            name: "Large v3 (Best)".into(),
            size_mb: 3100,
            url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v3.bin".into(),
            sha256: "64d182b440b98d5203c4f9bd541544d84c605196c4f7b845dfa11fb23594d1e2".into(),
            downloaded: false,
        },
    ]
}
```

### Download Implementation

```rust
use reqwest::Client;
use futures_util::StreamExt;
use sha2::{Sha256, Digest};
use std::io::Write;

pub async fn download_model_with_progress<F>(
    model: &WhisperModel,
    dest_path: &Path,
    on_progress: F,
) -> Result<(), DownloadError>
where
    F: Fn(f32) + Send + 'static,
{
    let client = Client::new();
    let response = client.get(&model.url).send().await?;

    let total_size = response.content_length()
        .ok_or(DownloadError::NoContentLength)?;

    let temp_path = dest_path.with_extension("tmp");
    let mut file = std::fs::File::create(&temp_path)?;
    let mut hasher = Sha256::new();
    let mut downloaded: u64 = 0;

    let mut stream = response.bytes_stream();

    while let Some(chunk) = stream.next().await {
        let chunk = chunk?;
        file.write_all(&chunk)?;
        hasher.update(&chunk);

        downloaded += chunk.len() as u64;
        let progress = downloaded as f32 / total_size as f32;
        on_progress(progress);
    }

    // Verify checksum
    let hash = format!("{:x}", hasher.finalize());
    if hash != model.sha256 {
        std::fs::remove_file(&temp_path)?;
        return Err(DownloadError::ChecksumMismatch {
            expected: model.sha256.clone(),
            actual: hash,
        });
    }

    // Move to final location
    std::fs::rename(&temp_path, dest_path)?;
    Ok(())
}
```

### Tauri Command with Events

```rust
#[tauri::command]
pub async fn download_model(
    model_id: String,
    window: tauri::Window,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let manifest = get_model_manifest();
    let model = manifest.iter()
        .find(|m| m.id == model_id)
        .ok_or("Model not found")?;

    let dest_path = state.storage.get_model_path(&model_id);

    download_model_with_progress(model, &dest_path, move |progress| {
        let _ = window.emit("model:download_progress", DownloadProgress {
            model_id: model_id.clone(),
            progress,
        });
    }).await.map_err(|e| e.to_string())?;

    let _ = window.emit("model:download_complete", &model_id);
    Ok(())
}
```

### File Locations

| File | Purpose |
|------|---------|
| `src-tauri/src/services/transcription/models.rs` | Model manifest & types |
| `src-tauri/src/services/storage/files.rs` | File storage service |
| `src-tauri/src/commands/models.rs` | Model Tauri commands |

### Error Types

```rust
#[derive(Error, Debug)]
pub enum DownloadError {
    #[error("Network error: {0}")]
    Network(#[from] reqwest::Error),

    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("No content length in response")]
    NoContentLength,

    #[error("Checksum mismatch: expected {expected}, got {actual}")]
    ChecksumMismatch { expected: String, actual: String },

    #[error("Download interrupted")]
    Interrupted,
}
```

### Testing

**Test Scenarios**:
- `test_model_manifest_has_all_models` - Verify 5 models in manifest
- `test_checksum_verification_pass` - Valid checksum passes
- `test_checksum_verification_fail` - Invalid checksum detected
- `test_model_path_resolution` - Correct platform paths

**Integration Test**: Download tiny model in CI, verify checksum

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-28 | 0.1 | Initial story draft | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

---

## QA Results
*To be filled by QA agent*
