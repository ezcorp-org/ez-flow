# Story 1.7: Record & Transcribe Flow

## Status

Draft

## Story

**As a** user,
**I want** to record speech and see the transcription immediately,
**so that** I can verify the speech-to-text is working.

## Acceptance Criteria

1. Tray menu "Start Recording" -> "Stop Recording" flow triggers transcription
2. After stopping, transcription runs automatically on recorded audio
3. Result window displays transcribed text with copy button
4. Temporary audio file cleaned up after transcription (unless user opts to keep)
5. Full flow works end-to-end: click record -> speak -> click stop -> see text
6. Transcription time logged for performance baseline

## Tasks / Subtasks

- [ ] **Task 1: Wire Recording to Transcription** (AC: 1, 2)
  - [ ] Modify `stop_recording` command to trigger transcription
  - [ ] Pass recorded audio buffer directly to WhisperEngine
  - [ ] Return TranscriptionResult from stop_recording

- [ ] **Task 2: Implement Full Tray Flow** (AC: 1, 5)
  - [ ] "Start Recording" begins audio capture
  - [ ] Menu item changes to "Stop Recording"
  - [ ] "Stop Recording" stops capture and starts transcription
  - [ ] Show processing state in tray (icon change or tooltip)
  - [ ] On completion, show result window

- [ ] **Task 3: Reuse Transcription Result Window** (AC: 3)
  - [ ] Use same result window from Story 1.6
  - [ ] Display "Recorded Audio" as filename
  - [ ] Show transcribed text
  - [ ] Copy button works the same

- [ ] **Task 4: Implement Temporary File Cleanup** (AC: 4)
  - [ ] Save recorded audio to temp file for processing
  - [ ] Delete temp file after successful transcription
  - [ ] Add setting for "Keep recorded audio" (default: false)
  - [ ] If keeping, move to user-accessible location

- [ ] **Task 5: Log Performance Metrics** (AC: 6)
  - [ ] Record audio duration (in seconds)
  - [ ] Record transcription time (in milliseconds)
  - [ ] Calculate real-time factor (transcription time / audio duration)
  - [ ] Log with tracing at info level
  - [ ] Include model name in log

- [ ] **Task 6: Update Recording State Management**
  - [ ] Create `src/lib/stores/recording.ts`
  - [ ] Track: isRecording, isProcessing, duration
  - [ ] Sync state between frontend and backend

- [ ] **Task 7: Create Unified Command** (AC: 2, 5)
  - [ ] Create `stop_recording_and_transcribe()` Tauri command
  - [ ] Combines stop_recording + transcribe in one call
  - [ ] Returns TranscriptionResult with metadata
  - [ ] Handles all error cases

- [ ] **Task 8: Add E2E Test** (AC: 5)
  - [ ] Test full record -> stop -> see text flow
  - [ ] Mock audio input for CI
  - [ ] Verify result window appears

## Dev Notes

### Dependencies on Previous Stories

This story builds on:
- **Story 1.3**: Audio capture (AudioCaptureService)
- **Story 1.4**: Whisper integration (WhisperEngine)
- **Story 1.6**: Result window UI (TranscriptionResult.svelte)

### Combined Command Implementation

```rust
// src-tauri/src/commands/audio.rs

#[tauri::command]
pub async fn stop_recording_and_transcribe(
    state: State<'_, AppState>,
) -> Result<TranscriptionResult, String> {
    let start = std::time::Instant::now();

    // Stop recording
    let mut capture = state.audio_capture.write().await;
    let audio = capture.stop().map_err(|e| e.to_string())?;

    let audio_duration_secs = audio.samples.len() as f32 / 16000.0;

    // Resample if needed
    let samples = resample_for_whisper(audio).map_err(|e| e.to_string())?;

    // Transcribe
    let engine = state.transcription_engine.read().await;
    let result = engine.transcribe(&samples).map_err(|e| e.to_string())?;

    let transcription_time_ms = start.elapsed().as_millis() as u64;
    let realtime_factor = transcription_time_ms as f32 / (audio_duration_secs * 1000.0);

    tracing::info!(
        audio_duration_secs = audio_duration_secs,
        transcription_time_ms = transcription_time_ms,
        realtime_factor = realtime_factor,
        model = %result.model_id,
        "Transcription completed"
    );

    Ok(result)
}
```

### Recording Store

```typescript
// src/lib/stores/recording.ts
import { writable, derived } from 'svelte/store';
import { invoke } from '@tauri-apps/api/core';

interface RecordingState {
  isRecording: boolean;
  isProcessing: boolean;
  startTime: number | null;
  result: TranscriptionResult | null;
  error: string | null;
}

function createRecordingStore() {
  const { subscribe, set, update } = writable<RecordingState>({
    isRecording: false,
    isProcessing: false,
    startTime: null,
    result: null,
    error: null,
  });

  return {
    subscribe,
    async startRecording() {
      await invoke('start_recording');
      update(s => ({ ...s, isRecording: true, startTime: Date.now(), error: null }));
    },
    async stopRecording() {
      update(s => ({ ...s, isRecording: false, isProcessing: true }));
      try {
        const result = await invoke<TranscriptionResult>('stop_recording_and_transcribe');
        update(s => ({ ...s, isProcessing: false, result }));
      } catch (error) {
        update(s => ({ ...s, isProcessing: false, error: String(error) }));
      }
    },
    reset() {
      set({ isRecording: false, isProcessing: false, startTime: null, result: null, error: null });
    }
  };
}

export const recording = createRecordingStore();
```

### Tray Menu State Updates

```rust
// Update menu based on recording state
fn update_tray_menu(app: &AppHandle, is_recording: bool) {
    let tray = app.tray_by_id("main").unwrap();

    if is_recording {
        // Show "Stop Recording"
        let menu = build_recording_menu(app);
        tray.set_menu(Some(menu)).unwrap();
    } else {
        // Show "Start Recording"
        let menu = build_default_menu(app);
        tray.set_menu(Some(menu)).unwrap();
    }
}
```

### Temp File Cleanup

```rust
// After successful transcription
fn cleanup_temp_audio(path: &Path, settings: &Settings) -> Result<(), std::io::Error> {
    if settings.keep_recordings {
        // Move to user documents folder
        let dest = get_recordings_dir()?.join(path.file_name().unwrap());
        std::fs::rename(path, dest)?;
    } else {
        // Delete temp file
        std::fs::remove_file(path)?;
    }
    Ok(())
}
```

### File Locations

| File | Purpose |
|------|---------|
| `src/lib/stores/recording.ts` | Recording state store |
| `src-tauri/src/commands/audio.rs` | Combined record+transcribe command |

### Performance Logging Output

```
INFO ez_flow::commands::audio: Transcription completed
  audio_duration_secs=5.2
  transcription_time_ms=2340
  realtime_factor=0.45
  model="ggml-base"
```

### Testing

**E2E Test** (`tests/e2e/record-transcribe.spec.ts`):

```typescript
test('should complete record-transcribe flow', async ({ page }) => {
  // Mock audio input for CI
  await page.evaluate(() => {
    window.__MOCK_AUDIO__ = true;
  });

  // Click Start Recording
  await page.click('[data-testid="start-recording-menu"]');

  // Wait and click Stop
  await page.waitForTimeout(2000);
  await page.click('[data-testid="stop-recording-menu"]');

  // Verify result window
  await expect(page.locator('[data-testid="transcription-result-window"]')).toBeVisible();
  await expect(page.locator('[data-testid="transcription-result-text"]')).not.toBeEmpty();
});
```

**Test IDs**:
```typescript
const testIds = {
  startRecordingMenu: 'start-recording-menu',
  stopRecordingMenu: 'stop-recording-menu',
  recordingIndicator: 'recording-indicator',
};
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-28 | 0.1 | Initial story draft | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

---

## QA Results
*To be filled by QA agent*
